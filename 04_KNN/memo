모델
입력데이터로 출력결과를 예측(설명)할 수 있는 수학 관계식(함수)

키, 몸무게
y = 0.7 * X + 30

[모델의 종류]
1. 지도학습
: 정답이 있는 데이터를 학습해서 예측하는 모델
(1) 회귀
    출력값 : 연속형 숫자 (점수, 가격, 온도)
    대표 모델 : 선형회귀, 다중회귀, 다항회귀

(2) 분류 (그룹 예측)
    출력값 : 범주형 (합격/불합격, 스팸/정상, 개/고양이)
    대표 모델 : 로지스틱 회귀, 서포트 벡터머신(SVM), K-최근접 이웃(KNN)

2. 비지도 학습
: 정답없이 데이터 구조나 패턴을 찾는 패턴
    1. 장바구니 분석(연관분석)
    2. 군집분석 (거리측도)
    3. DBSCAN 알고리즘 (밀도 기반)
    대표 모델 : K-means

선형회귀:
단순 선형회귀 : 독립변수 1개
다중 선형회귀 : 독립변수 2개


# 분류 알고리즘

## 1. SVM 알고리즘
⚫ SVM 주요 개념
1) 결정경계(Decision Boundary): 두 클래스를 구분하는 기준선 (decision_function = 0)
2) 마진(Margin): 결정경계와 서포트벡터(Support Vector) 간의 거리
3) 서포트벡터(Support Vector): 마진 경계선 위에 위치한 데이터 포인트들
4) 초평면(Hyperplane): 결정경계를 일반화한 개념 (2D에서는 직선, 3D에서는 평면)

⚫ 혼동행렬 (confusion matrix)
                예측
        negative    positive
실제(N)     TN          FP
실제(P)     FN          TP
TN : True Negative
FP : False Positive
FN : False Negative
TP : True Positive

Accuracy (정확도) = (TP + TN) / (TP + TN + FP + FN)
→ 전체 예측 중 맞춘 비율

Precision (정밀도) = TP / (TP + FP)
→ “합격”이라고 예측한 것 중 실제 합격 비율

NPV (Negative Predictive Value, 0의 정밀도) = TN / (TN + FN)
→ “불합격”이라고 예측한 것 중 실제 불합격 비율

Recall TPR(재현율, 민감도) = TP / (TP + FN)
→ 실제 합격자 중 모델이 맞게 예측한 비율

FPR (False Positive Rate, 거짓긍정률) =
FP / (FP + TN)
→ 실제 불합격자 중 “합격”으로 잘못 예측한 비율

Specificity (특이도) = TN / (TN + FP)
→ 실제 불합격자 중 모델이 맞게 예측한 비율


F1-score = 2 × (Precision × Recall) / (Precision + Recall)
→ 정밀도와 재현율의 조화평균

🌈 classification_report(실제 데이터, 예측데이터)

⚫ ROC / AUC (모델 성능 평가 지표)
1. ROC (Receiver Operating Characteristic)
1) X축: FPR = FP / (FP + TN) → 거짓긍정률
2) Y축: TPR = TP / (TP + FN) → 재현율(민감도)
3) 임계값(threshold)을 바꾸며 TPR과 FPR 변화를 그린 곡선

2. AUC (Area Under Curve)
1) ROC 곡선 아래 면적
2) 값이 1에 가까울수록 좋은 모델

## 2. KNN 알고리즘
# K-최근접 이웃(KNN : K-Nearest Neighbors)
새로운 데이터가 들어왔을 때, 기존 데이터 중 가장 가까운 K개의 점(이웃) 을 찾아
그 중 가장 많은 클래스(혹은 평균값) 으로 새 데이터를 분류하는 알고리즘

